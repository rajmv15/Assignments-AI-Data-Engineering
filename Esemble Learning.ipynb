{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7696344-4ce2-4a70-9b8b-68a0e0fd37e4",
   "metadata": {},
   "source": [
    "\n",
    " - **Blending**\n",
    " - **Bagging**\n",
    " - **Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "856cc507-12cd-44b3-b542-31db80364fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750b004-a7c1-45d5-9d00-a96560c18ebd",
   "metadata": {},
   "source": [
    "# Problem 1: Blending scratch mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f137052-f074-4cec-95ad-4781c1453f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0          2003       196.0         706  ...           0           61   \n",
       "1          1976         0.0         978  ...         298            0   \n",
       "2          2002       162.0         486  ...           0           42   \n",
       "3          1970         0.0         216  ...           0           35   \n",
       "4          2000       350.0         655  ...         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "data=pd.read_csv('Data/house price data/train.csv').select_dtypes(include='number')\n",
    "\n",
    "# handling of missing values\n",
    "data.isnull().sum()\n",
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baea1e00-202b-43b6-852d-342305bb36ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(1460, 37), y shape:(1460,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "X = data.drop(['SalePrice'],axis=1).values\n",
    "y = data['SalePrice'].values\n",
    "\n",
    "X = np.log1p(X)\n",
    "y = np.log1p(y)\n",
    "\n",
    "print('X shape:{}, y shape:{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368e7dca-5142-4c94-8973-787f4e979ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd447f7f-fb05-4cbb-a3b6-737cf32935e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "Blend:0.022\n"
     ]
    }
   ],
   "source": [
    "# Example number 1\n",
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions = list()\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    \n",
    "predictions_ndarray = np.array(predictions)\n",
    "blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404d5c74-9e6e-4d1b-a796-d26c7ab2b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "Blend:0.023\n"
     ]
    }
   ],
   "source": [
    "# Example number 2\n",
    "svr_model1 = SVR(C=1)\n",
    "svr_model2 = SVR(C=5)\n",
    "svr_model3 = SVR(C=10)\n",
    "svr_model1.fit(X_train,y_train)\n",
    "svr_model2.fit(X_train,y_train)\n",
    "svr_model3.fit(X_train,y_train)\n",
    "svr_pred1 = svr_model1.predict(X_test)\n",
    "svr_pred2 = svr_model2.predict(X_test)\n",
    "svr_pred3 = svr_model2.predict(X_test)\n",
    "    \n",
    "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932fe535-9751-4a7b-a7ec-d80b4712f028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "Blend:0.022\n"
     ]
    }
   ],
   "source": [
    "# Example 3\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trans = std_scaler.transform(X_train)\n",
    "X_test_trans = std_scaler.transform(X_test)\n",
    "\n",
    "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions2 = list()\n",
    "for model in models2:\n",
    "    model.fit(X_train_trans,y_train)\n",
    "    predictions2.append(model.predict(X_test_trans))\n",
    "    \n",
    "predictions_ndarray2 = np.array(predictions)\n",
    "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,blend2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a123e841-d71f-43ad-8c29-8e83927b6c98",
   "metadata": {},
   "source": [
    "# Problem 2: Scratch mounting of bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a3109d-379c-4bdc-849c-c48a77df6015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1991e510-d57f-455b-ada8-4a13158f3f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of bagging pred:[12.25781018 12.00773981 11.56490218 11.0209482  11.89735932 12.60472669\n",
      " 12.59220741 11.86406303 12.27052756 12.36113397 12.11548091 11.12838367\n",
      " 12.18649386 12.82128078 12.31910248 11.60539099 11.62213085 11.72839201\n",
      " 12.32107768 11.74982214 11.65550567 11.71290923 12.42377148 12.66660672\n",
      " 11.4749905  12.20612542 11.72834793 12.16725904 12.86494783 11.83589528\n",
      " 11.86315248 11.68659899 11.65744956 11.49411183 11.90581371 12.73189308\n",
      " 11.76761403 11.30574824 12.60565707 11.67492642 11.97189583 11.93486415\n",
      " 11.53293091 11.74298774 12.13173827 12.09642135 11.73163762 12.04139342\n",
      " 12.3934759  12.387204   11.5938642  12.67833256 11.50486925 12.34734819\n",
      " 12.25089831 11.51290754 11.68953193 12.03161852 11.74564378 12.13535004\n",
      " 12.05905897 12.53183387 11.48497146 11.56815769 12.00872828 11.79338659\n",
      " 11.74946287 12.3373183  12.08495867 11.94699061 12.01896958 11.49884952\n",
      " 12.65849332 11.95045468 12.01314801 12.2646974  12.04329547 11.86209502\n",
      " 12.92208333 12.22241589 12.18280714 11.74789516 11.79758841 11.96404148\n",
      " 12.19222809 12.02886818 11.99980867 12.02568851 12.14218659 12.09982482\n",
      " 12.20024787 11.98374621 11.58035304 11.49854593 11.77168392 11.75484805\n",
      " 11.68189589 11.82141761 11.94860047 11.88906072 11.98585921 11.81101929\n",
      " 11.63764146 11.64858042 11.79703451 12.14972015 12.11081098 12.1586146\n",
      " 11.92171686 12.68637318 11.92443487 12.09030299 11.90928349 12.18312712\n",
      " 12.36817088 12.04313444 12.30038176 11.75944756 12.05778526 12.49834639\n",
      " 11.87475675 12.28891716 12.74241422 11.95535723 12.20320309 12.14328756\n",
      " 12.60499457 11.64641506 12.22847787 12.26323617 12.49906312 11.41171568\n",
      " 11.76197399 11.79975634 11.46961195 12.22388777 12.99362144 12.68279786\n",
      " 12.3851558  11.85316862 11.71901215 12.54425055 12.14410725 12.18399576\n",
      " 11.53200446 12.22071332 11.49762479 12.12791549 12.33775166 11.60348324\n",
      " 12.12902204 12.02254067 11.69406535 12.11512468 12.17955682 12.58597647\n",
      " 11.5142385  11.83236935 11.49811289 11.81556985 10.83409738 11.49062511\n",
      " 11.90795891 11.88886631 11.62666707 11.79566914 11.98271453 11.84503877\n",
      " 11.86129022 11.58543379 12.35661599 11.87725353 12.31573002 12.53100769\n",
      " 12.21220532 11.81543566 12.22983649 12.19986341 11.82105823 12.05088519\n",
      " 11.8343862  12.06805951 11.91456029 11.89133242 12.55767453 11.90503599\n",
      " 12.5735829  12.59249117 11.93947249 11.70744783 11.53627764 11.93276551\n",
      " 11.489222   12.24655159 11.78191197 12.46247615 12.32708747 11.96853924\n",
      " 11.88356441 11.04193037 12.23432108 12.34975594 12.10971484 12.06184845\n",
      " 12.46583316 11.7022267  12.14260578 12.59338675 12.41675293 12.34499726\n",
      " 12.20238901 11.64489871 11.97478786 11.69801762 12.54057851 12.44839643\n",
      " 11.72038431 11.37884673 12.25849631 11.14306648 13.00202785 11.69281289\n",
      " 11.8890972  12.21364068 11.69613085 11.72095484 12.1646201  12.05596463\n",
      " 11.94046769 12.02430028 11.67657401 12.09797776 11.47499846 11.73325161\n",
      " 12.63088827 11.67891512 12.59720014 11.69682064 11.79075479 12.62023138\n",
      " 12.74165361 12.06302374 11.8602322  11.92798931 11.82723683 11.63965374\n",
      " 11.90907648 11.91823821 11.98089947 11.97644006 11.63564484 11.59118072\n",
      " 12.09134308 12.08935    11.6225595  11.66887091 12.14538924 11.43518214\n",
      " 12.62541987 11.75804728 12.22567728 12.15641717 12.27755744 12.06541047\n",
      " 11.58558014 12.22518324 11.77071536 12.12709153 11.91592498 11.4934439\n",
      " 12.12482482 12.11092546 11.38813463 11.64913052 12.11537418 11.41598007\n",
      " 11.66630664 11.80258618 11.95899572 11.87708353 11.85758956 11.81463453\n",
      " 11.7816476  11.93245587 12.37112628 12.44323496 11.7120507  11.34078978\n",
      " 12.36562415 11.51992782 11.37364782 12.51356676]\n",
      "average of bagging mse:0.022\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "class BaggingScratch():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.predictions = list()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for model in models:\n",
    "            model.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        predictions = list()\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        self.predictions = np.mean(np.array(predictions),axis=0)\n",
    "        return self.predictions\n",
    "    def mse(self, y):\n",
    "        mse = (mean_squared_error(y,self.predictions))\n",
    "        return mse\n",
    "    \n",
    "\n",
    "bag = BaggingScratch(models)\n",
    "bag.fit(X_train,y_train)\n",
    "print(\"average of bagging pred:{}\".format(bag.predict(X_test)))\n",
    "print(\"average of bagging mse:{:.3f}\".format(bag.mse(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06fd6ac4-a7b3-4506-8784-4ea714191c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset()\n",
    "# Splitting into train and tests(used for base models)\n",
    "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "\n",
    "# Splitting into train and validations(used for ensemble model)\n",
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea892736-5801-4a2c-b0ad-bf61a041c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to return the models in a form of a tuple\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr',LinearRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "# a function to fit and blend all of our models\n",
    "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
    "    # fit and predict using the validation data\n",
    "    \n",
    "    # a list to hold the predicted data from the base model for the blender model\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        model.fit(X_train_1, y_train_1)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # defining our blender\n",
    "    blender = LinearRegression()\n",
    "    \n",
    "    # fitting our blender using our meta values and y validation set\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# a function to make predictions with our ensemble\n",
    "def pred_ensemble(models, blender, X_test_1):\n",
    "    # a list to hold te predictions for the blender\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        \n",
    "        # predicting using our base models\n",
    "        y_pred = model.predict(X_test_1)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # predicting using our blender\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
    "y_pred = pred_ensemble(models, blender, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "220fe874-42c9-4164-9b75-974001bb24e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values used\n",
      "Train:(4000, 20) Val:(1000, 20) Test:(5000, 20)\n",
      "Accuracy score\n",
      "------------------\n",
      "Blended ensemble:0.023\n",
      "Logistic regression:0.110\n"
     ]
    }
   ],
   "source": [
    "# printing mse\n",
    "print(\"Values used\")\n",
    "print(\"Train:{} Val:{} Test:{}\".format(X_train_1.shape, X_val.shape, X_test_1.shape))\n",
    "print(\"Accuracy score\")\n",
    "print(\"------------------\")\n",
    "print(\"Blended ensemble:{:.3f}\".format(mean_squared_error(y_test_1,y_pred)))\n",
    "\n",
    "# on individual model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_1, y_train_1)\n",
    "y_pred1= model.predict(X_test_1)\n",
    "print(\"Logistic regression:{:.3f}\".format(mean_squared_error(y_test_1,y_pred1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
